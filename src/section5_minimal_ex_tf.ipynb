{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generation (same as in section 4, but with the np.savez(...) line of code added)\n",
    "\n",
    "observations = 1000\n",
    "\n",
    "xs = np.random.uniform(low=-10, high=10, size=(observations, 1)) # 1000x1\n",
    "zs = np.random.uniform(-10, 10, (observations, 1)) # 1000x1\n",
    "\n",
    "generated_inputs = np.column_stack((xs, zs)) # 1000x2\n",
    "noise = np.random.uniform(-1, 1, (observations, 1)) # 1000x1\n",
    "generated_targets = 2*xs - 3*zs + 5 + noise # 1000x1\n",
    "\n",
    "np.savez('section5_tf_intro', inputs=generated_inputs, targets=generated_targets)\n",
    "# .npz is basically TF's file type, which stores arrays/tensors.\n",
    "# Common to open data like a .csv, preprocess it, then save as .npz file. Then later, build algorithm w/ .npz.\n",
    "# Note: The above keys, \"inputs\" and \"targets\" can be called anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 81.9504 \n",
      "Epoch 2/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 5.4618\n",
      "Epoch 3/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - loss: 1.8630\n",
      "Epoch 4/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - loss: 0.7454\n",
      "Epoch 5/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - loss: 0.4516\n",
      "Epoch 6/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - loss: 0.3797\n",
      "Epoch 7/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.3389\n",
      "Epoch 8/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - loss: 0.3761\n",
      "Epoch 9/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - loss: 0.3307\n",
      "Epoch 10/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - loss: 0.3548\n",
      "Epoch 11/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - loss: 0.3273\n",
      "Epoch 12/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - loss: 0.3416\n",
      "Epoch 13/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - loss: 0.3542\n",
      "Epoch 14/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - loss: 0.3447\n",
      "Epoch 15/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - loss: 0.3750\n",
      "Epoch 16/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - loss: 0.3509\n",
      "Epoch 17/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 0.3247\n",
      "Epoch 18/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - loss: 0.3448\n",
      "Epoch 19/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 0.3443\n",
      "Epoch 20/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 0.3439\n",
      "Epoch 21/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - loss: 0.3508\n",
      "Epoch 22/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - loss: 0.3253\n",
      "Epoch 23/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.3429\n",
      "Epoch 24/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.3392\n",
      "Epoch 25/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - loss: 0.3527\n",
      "Epoch 26/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - loss: 0.3430\n",
      "Epoch 27/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - loss: 0.3315\n",
      "Epoch 28/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 0.3650\n",
      "Epoch 29/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - loss: 0.3397\n",
      "Epoch 30/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - loss: 0.3599\n",
      "Epoch 31/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - loss: 0.3413\n",
      "Epoch 32/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - loss: 0.3801\n",
      "Epoch 33/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - loss: 0.3355\n",
      "Epoch 34/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - loss: 0.3452\n",
      "Epoch 35/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - loss: 0.3665\n",
      "Epoch 36/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - loss: 0.3367\n",
      "Epoch 37/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 0.3729\n",
      "Epoch 38/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 0.3425\n",
      "Epoch 39/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - loss: 0.3353\n",
      "Epoch 40/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - loss: 0.3337\n",
      "Epoch 41/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - loss: 0.3430\n",
      "Epoch 42/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - loss: 0.3505\n",
      "Epoch 43/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 0.3505\n",
      "Epoch 44/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 0.3405\n",
      "Epoch 45/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - loss: 0.3568\n",
      "Epoch 46/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - loss: 0.3458\n",
      "Epoch 47/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - loss: 0.3342\n",
      "Epoch 48/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.3686\n",
      "Epoch 49/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - loss: 0.3587\n",
      "Epoch 50/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - loss: 0.3452\n",
      "Epoch 51/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - loss: 0.3617\n",
      "Epoch 52/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - loss: 0.3493\n",
      "Epoch 53/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - loss: 0.3298\n",
      "Epoch 54/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - loss: 0.3472\n",
      "Epoch 55/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - loss: 0.3447\n",
      "Epoch 56/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - loss: 0.3533\n",
      "Epoch 57/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - loss: 0.3411\n",
      "Epoch 58/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 0.3527\n",
      "Epoch 59/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - loss: 0.3417\n",
      "Epoch 60/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - loss: 0.3449\n",
      "Epoch 61/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - loss: 0.3515\n",
      "Epoch 62/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - loss: 0.3341\n",
      "Epoch 63/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - loss: 0.3418\n",
      "Epoch 64/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - loss: 0.3695\n",
      "Epoch 65/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 0.3478\n",
      "Epoch 66/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - loss: 0.3324\n",
      "Epoch 67/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 0.3445\n",
      "Epoch 68/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - loss: 0.3668\n",
      "Epoch 69/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - loss: 0.3647\n",
      "Epoch 70/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 0.3388\n",
      "Epoch 71/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 0.3430\n",
      "Epoch 72/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 0.3459\n",
      "Epoch 73/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 0.3339\n",
      "Epoch 74/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - loss: 0.3422\n",
      "Epoch 75/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - loss: 0.3458\n",
      "Epoch 76/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - loss: 0.3529\n",
      "Epoch 77/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - loss: 0.3557\n",
      "Epoch 78/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - loss: 0.3383\n",
      "Epoch 79/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - loss: 0.3649\n",
      "Epoch 80/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 0.3388\n",
      "Epoch 81/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 0.3222\n",
      "Epoch 82/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.3552\n",
      "Epoch 83/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - loss: 0.3479\n",
      "Epoch 84/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - loss: 0.3587\n",
      "Epoch 85/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 0.3364\n",
      "Epoch 86/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 0.3615\n",
      "Epoch 87/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - loss: 0.3517\n",
      "Epoch 88/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 0.3412\n",
      "Epoch 89/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - loss: 0.3817\n",
      "Epoch 90/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - loss: 0.3430\n",
      "Epoch 91/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - loss: 0.3622\n",
      "Epoch 92/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - loss: 0.3496\n",
      "Epoch 93/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - loss: 0.3503\n",
      "Epoch 94/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 0.3576\n",
      "Epoch 95/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - loss: 0.3419\n",
      "Epoch 96/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - loss: 0.3491\n",
      "Epoch 97/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 0.3265\n",
      "Epoch 98/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - loss: 0.3630\n",
      "Epoch 99/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - loss: 0.3475\n",
      "Epoch 100/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - loss: 0.3602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1bfed020f50>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Approach A (simpler with default initializers and learning rate): Load the .npz file and Train the model\n",
    "\n",
    "training_data = np.load('section5_tf_intro.npz')\n",
    "# Note: Access tensors using keys similar to a dict -> Ex: training_data['inputs'] or training_data['targets']\n",
    "\n",
    "input_size = 2 # xs and zs\n",
    "output_size = 1 # Y or generated_targets\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(output_size)\n",
    "    ]\n",
    ")\n",
    "# Sequential() function specifies how the model will be \"laid down\" (\"stacks layers\") and can also initialize weights\n",
    "# Dense(output size) takes inputs provided to the model and calculates the dot product of inputs and weights and adds bias\n",
    "# ^ (optional) also applies activation function\n",
    "\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "# model.compile(optimizer, loss) configures the model for training. \"sgd\" = stochastic gradient descent\n",
    "# Use MSE for L2-norm. \n",
    "# Note: Another loss for regression in \"Huber Loss,\" which is better when we have outliers, as it is less sensitive to them. Combines absolute and squared loss.\n",
    "\n",
    "model.fit(training_data['inputs'], training_data['targets'], epochs=100, verbose=1)\n",
    "# model.fit(inputs, targets) fits (trains) the model\n",
    "# epochs = iterations over the full dataset\n",
    "# verbose=0 -> no output. verbose=1 -> progress bar + details. verbose=2 -> details, no progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - loss: 60.7106 \n",
      "Epoch 2/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - loss: 1.7136\n",
      "Epoch 3/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - loss: 0.4623\n",
      "Epoch 4/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - loss: 0.3898\n",
      "Epoch 5/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - loss: 0.3609\n",
      "Epoch 6/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 0.5772\n",
      "Epoch 7/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - loss: 0.3784\n",
      "Epoch 8/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - loss: 0.3744\n",
      "Epoch 9/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - loss: 0.3751\n",
      "Epoch 10/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - loss: 0.3692\n",
      "Epoch 11/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - loss: 0.3950\n",
      "Epoch 12/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - loss: 0.4659\n",
      "Epoch 13/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - loss: 0.4140\n",
      "Epoch 14/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 0.4366\n",
      "Epoch 15/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - loss: 0.4244\n",
      "Epoch 16/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - loss: 0.3792\n",
      "Epoch 17/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.3679\n",
      "Epoch 18/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - loss: 0.5462\n",
      "Epoch 19/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - loss: 0.4259\n",
      "Epoch 20/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - loss: 0.3760\n",
      "Epoch 21/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - loss: 0.3998\n",
      "Epoch 22/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - loss: 0.4112\n",
      "Epoch 23/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - loss: 0.4260\n",
      "Epoch 24/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - loss: 0.4585\n",
      "Epoch 25/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - loss: 0.4123\n",
      "Epoch 26/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - loss: 0.3924\n",
      "Epoch 27/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - loss: 0.4347\n",
      "Epoch 28/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - loss: 0.3792\n",
      "Epoch 29/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 0.3655\n",
      "Epoch 30/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - loss: 0.5125\n",
      "Epoch 31/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - loss: 0.3906\n",
      "Epoch 32/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - loss: 0.3576\n",
      "Epoch 33/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.3768\n",
      "Epoch 34/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - loss: 0.3714\n",
      "Epoch 35/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - loss: 0.3859\n",
      "Epoch 36/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - loss: 0.3908\n",
      "Epoch 37/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 0.3914\n",
      "Epoch 38/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 0.4327\n",
      "Epoch 39/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - loss: 0.3788\n",
      "Epoch 40/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - loss: 0.4090\n",
      "Epoch 41/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 0.4825\n",
      "Epoch 42/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.4089\n",
      "Epoch 43/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 0.4499\n",
      "Epoch 44/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 0.3763\n",
      "Epoch 45/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - loss: 0.3877\n",
      "Epoch 46/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - loss: 0.3781\n",
      "Epoch 47/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - loss: 0.4410\n",
      "Epoch 48/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - loss: 0.3871\n",
      "Epoch 49/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - loss: 0.3816\n",
      "Epoch 50/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - loss: 0.3571\n",
      "Epoch 51/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - loss: 0.3608\n",
      "Epoch 52/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - loss: 0.3717\n",
      "Epoch 53/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - loss: 0.4121\n",
      "Epoch 54/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - loss: 0.3751\n",
      "Epoch 55/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 0.3454\n",
      "Epoch 56/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - loss: 0.4321\n",
      "Epoch 57/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - loss: 0.3932\n",
      "Epoch 58/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - loss: 0.3984\n",
      "Epoch 59/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - loss: 0.4359\n",
      "Epoch 60/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - loss: 0.3426\n",
      "Epoch 61/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - loss: 0.3964\n",
      "Epoch 62/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - loss: 0.3477\n",
      "Epoch 63/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - loss: 0.3816\n",
      "Epoch 64/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 0.3911\n",
      "Epoch 65/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - loss: 0.5728\n",
      "Epoch 66/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - loss: 0.4210\n",
      "Epoch 67/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - loss: 0.4161\n",
      "Epoch 68/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - loss: 0.3640\n",
      "Epoch 69/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 0.3495\n",
      "Epoch 70/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - loss: 0.3738\n",
      "Epoch 71/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - loss: 0.3302\n",
      "Epoch 72/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.4849\n",
      "Epoch 73/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - loss: 0.3902\n",
      "Epoch 74/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - loss: 0.4032\n",
      "Epoch 75/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - loss: 0.3440\n",
      "Epoch 76/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - loss: 0.3790\n",
      "Epoch 77/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - loss: 0.4098\n",
      "Epoch 78/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - loss: 0.3728\n",
      "Epoch 79/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 0.3925\n",
      "Epoch 80/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - loss: 0.3987\n",
      "Epoch 81/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - loss: 0.5677\n",
      "Epoch 82/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - loss: 0.4343\n",
      "Epoch 83/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - loss: 0.4503\n",
      "Epoch 84/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - loss: 0.3722\n",
      "Epoch 85/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - loss: 0.3658\n",
      "Epoch 86/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - loss: 0.3706\n",
      "Epoch 87/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - loss: 0.3514\n",
      "Epoch 88/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - loss: 0.4663\n",
      "Epoch 89/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 0.4303\n",
      "Epoch 90/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 0.3553\n",
      "Epoch 91/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - loss: 0.3691\n",
      "Epoch 92/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 0.4313\n",
      "Epoch 93/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 0.4038\n",
      "Epoch 94/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.4430\n",
      "Epoch 95/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 0.4058\n",
      "Epoch 96/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - loss: 0.4307\n",
      "Epoch 97/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - loss: 0.4291\n",
      "Epoch 98/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 0.3646\n",
      "Epoch 99/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - loss: 0.4098\n",
      "Epoch 100/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - loss: 0.3946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1bff0401040>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Approach B: Load the .npz file and Train the model, but with initializers in Dense() and custom_optomizer in compile\n",
    "# This approach is more explicit to match the weight/bias initializer and learning rate from the numpy example in section 4\n",
    "\n",
    "training_data = np.load('tf_intro.npz')\n",
    "\n",
    "input_size = 2\n",
    "output_size = 1\n",
    "\n",
    "# Below 3 lines are updated\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(\n",
    "            output_size,\n",
    "            kernel_initializer=tf.random_uniform_initializer(minval=-0.1, maxval=0.1), # kernel means weight here\n",
    "            bias_initializer=tf.random_uniform_initializer(-0.1, 0.1)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "custom_optimizer = tf.keras.optimizers.SGD(learning_rate=0.02)\n",
    "model.compile(optimizer=custom_optimizer, loss='mean_squared_error')\n",
    "\n",
    "model.fit(training_data['inputs'], training_data['targets'], epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.9891962]\n",
      " [-2.9139507]] , [5.0181236]\n"
     ]
    }
   ],
   "source": [
    "# Extract the weights and bias\n",
    "\n",
    "weights = model.layers[0].get_weights()[0]\n",
    "bias = model.layers[0].get_weights()[1]\n",
    "print(weights, ',', bias) # [[ 2.0561464] [-3.0132828]] , [5.0186114]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 13. ]\n",
      " [  3.7]\n",
      " [-12.7]\n",
      " [ 35.8]\n",
      " [  6.1]]\n",
      "[[ 12.8]\n",
      " [  2.5]\n",
      " [-13.9]\n",
      " [ 37.5]\n",
      " [  6.1]]\n"
     ]
    }
   ],
   "source": [
    "# Make \"predictions\" (using training data and compare to targets)\n",
    "\n",
    "predictions = model.predict_on_batch(training_data['inputs'])\n",
    "# model.predict_on_batch(data) calculates the outputs given inputs\n",
    "\n",
    "# Compare the first 5 observations\n",
    "print(predictions.round(1)[:5])\n",
    "print(training_data['targets'].round(1)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the data\n",
    "\n",
    "plt.plot(np.squeeze(predictions), np.squeeze(training_data['targets']))\n",
    "plt.xlabel('outputs')\n",
    "plt.ylabel('targets')\n",
    "plt.show()\n",
    "\n",
    "# Note to self: Not sure why np.squeeze is needed since predictions and targets are both 1000x1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
